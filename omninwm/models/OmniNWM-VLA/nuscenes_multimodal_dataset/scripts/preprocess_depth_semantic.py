#!/usr/bin/env python3
"""
é¢„å¤„ç†è„šæœ¬ï¼šç”Ÿæˆæ·±åº¦å›¾å’Œè¯­ä¹‰åˆ†å‰²å›¾
åœ¨ç”ŸæˆShareGPTæ•°æ®é›†ä¹‹å‰è¿è¡Œæ­¤è„šæœ¬
"""

import os
import sys
import json
import argparse
import logging
from pathlib import Path
from tqdm import tqdm
import torch
import numpy as np
from PIL import Image

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

def check_gpu():
    """æ£€æŸ¥GPUçŠ¶æ€"""
    if torch.cuda.is_available():
        print(f"âœ… GPUå¯ç”¨: {torch.cuda.get_device_name(0)}")
        print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
        return True
    else:
        print("âš ï¸  GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
        return False

def initialize_processors(config_path):
    """åˆå§‹åŒ–æ·±åº¦å’Œè¯­ä¹‰å¤„ç†å™¨"""
    
    # è¯»å–é…ç½®
    with open(config_path, 'r') as f:
        import yaml
        config = yaml.safe_load(f)
    
    # åˆå§‹åŒ–æ·±åº¦å¤„ç†å™¨
    from src.processors.depth_processor import DepthProcessor
    depth_config = config.get('depth', {})
    depth_processor = DepthProcessor(
        model_name=depth_config.get('model_name', 'ZoeDepth'),
        model_path=depth_config.get('model_path'),
        device='cuda' if torch.cuda.is_available() else 'cpu',
        use_local_weights=True if depth_config.get('model_path') else False
    )
    print("âœ… æ·±åº¦å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    # åˆå§‹åŒ–è¯­ä¹‰åˆ†å‰²å¤„ç†å™¨
    from src.processors.semantic_processor import SemanticProcessor
    semantic_config = config.get('semantic', {})
    semantic_processor = SemanticProcessor(
        model_name=semantic_config.get('model_name', 'SegFormer'),
        model_path=semantic_config.get('model_path'),
        device='cuda' if torch.cuda.is_available() else 'cpu',
        use_local_weights=True if semantic_config.get('model_path') else False
    )
    print("âœ… è¯­ä¹‰åˆ†å‰²å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    return depth_processor, semantic_processor, config

def process_single_image(image_path, depth_processor, semantic_processor, output_dir, dataroot):
    """å¤„ç†å•å¼ å›¾åƒ"""
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    depth_dir = output_dir / 'depth'
    semantic_dir = output_dir / 'semantic'
    depth_dir.mkdir(parents=True, exist_ok=True)
    semantic_dir.mkdir(parents=True, exist_ok=True)
    
    # æ„å»ºè¾“å‡ºè·¯å¾„ï¼ˆä½¿ç”¨é…ç½®ä¸­çš„datarootè€Œä¸æ˜¯ç¡¬ç¼–ç è·¯å¾„ï¼‰
    rel_path = Path(image_path).relative_to(dataroot)
    depth_path = depth_dir / rel_path.parent / f"{rel_path.stem}_depth.png"
    semantic_path = semantic_dir / rel_path.parent / f"{rel_path.stem}_semantic.png"
    
    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
    if depth_path.exists() and semantic_path.exists():
        return True, "å·²å­˜åœ¨"
    
    try:
        # è¯»å–å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        
        # ç”Ÿæˆæ·±åº¦å›¾
        if not depth_path.exists():
            depth_path.parent.mkdir(parents=True, exist_ok=True)
            depth_map = depth_processor.process(image)  # è¿”å›å•ä½ï¼šç±³
            # ä¿å­˜æ·±åº¦å›¾ï¼ˆ16ä½PNGï¼Œç»Ÿä¸€ä½¿ç”¨æ¯«ç±³å•ä½ï¼‰
            depth_mm = (depth_map * 1000).astype(np.uint16)
            Image.fromarray(depth_mm).save(depth_path)
        
        # ç”Ÿæˆè¯­ä¹‰åˆ†å‰²å›¾
        if not semantic_path.exists():
            semantic_path.parent.mkdir(parents=True, exist_ok=True)
            semantic_map = semantic_processor.process(image)
            # ä¿å­˜è¯­ä¹‰å›¾ï¼ˆç´¢å¼•å›¾ï¼‰
            Image.fromarray(semantic_map.astype(np.uint8)).save(semantic_path)
        
        return True, "æˆåŠŸ"
        
    except Exception as e:
        return False, str(e)

def process_nuscenes_dataset(config_path, max_samples=None, batch_size=1):
    """å¤„ç†æ•´ä¸ªnuScenesæ•°æ®é›†"""
    
    logger = setup_logging()
    
    print("="*70)
    print("ğŸš€ nuScenesæ·±åº¦å’Œè¯­ä¹‰å›¾é¢„å¤„ç†")
    print("="*70)
    
    # æ£€æŸ¥GPU
    check_gpu()
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    print("\nåˆå§‹åŒ–æ¨¡å‹...")
    depth_processor, semantic_processor, config = initialize_processors(config_path)
    
    # è®¾ç½®è·¯å¾„
    dataroot = Path(config['dataset']['nuscenes_dataroot'])
    output_dir = Path(config['dataset']['output_directory'])
    
    # åŠ è½½nuScenes
    print("\nåŠ è½½nuScenesæ•°æ®é›†...")
    from nuscenes.nuscenes import NuScenes
    nusc = NuScenes(
        version=config['dataset']['nuscenes_version'],
        dataroot=str(dataroot),
        verbose=False
    )
    print(f"âœ… åŠ è½½ {len(nusc.scene)} ä¸ªåœºæ™¯")
    
    # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„å›¾åƒ
    print("\næ”¶é›†å›¾åƒè·¯å¾„...")
    camera_channels = config['cameras']['channels']
    image_paths = []
    
    for scene in tqdm(nusc.scene, desc="æ‰«æåœºæ™¯"):
        # è·å–åœºæ™¯ä¸­çš„æ‰€æœ‰æ ·æœ¬
        sample_token = scene['first_sample_token']
        while sample_token:
            sample = nusc.get('sample', sample_token)
            
            # è·å–æ‰€æœ‰æ‘„åƒå¤´çš„å›¾åƒè·¯å¾„
            for camera in camera_channels:
                if camera in sample['data']:
                    sample_data = nusc.get('sample_data', sample['data'][camera])
                    image_path = dataroot / sample_data['filename']
                    if image_path.exists():
                        image_paths.append(image_path)
            
            sample_token = sample['next']
            
            # é™åˆ¶æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            if max_samples and len(image_paths) >= max_samples * len(camera_channels):
                break
        
        if max_samples and len(image_paths) >= max_samples * len(camera_channels):
            break
    
    print(f"æ‰¾åˆ° {len(image_paths)} å¼ å›¾åƒéœ€è¦å¤„ç†")
    
    # å¤„ç†å›¾åƒ
    print("\nå¼€å§‹å¤„ç†å›¾åƒ...")
    success_count = 0
    skip_count = 0
    error_count = 0
    
    # ä½¿ç”¨æ‰¹å¤„ç†æé«˜æ•ˆç‡
    with tqdm(total=len(image_paths), desc="å¤„ç†è¿›åº¦") as pbar:
        for i in range(0, len(image_paths), batch_size):
            batch_paths = image_paths[i:i+batch_size]
            
            for image_path in batch_paths:
                success, message = process_single_image(
                    image_path, 
                    depth_processor, 
                    semantic_processor,
                    output_dir,
                    dataroot  # ä¼ é€’datarootå‚æ•°
                )
                
                if success:
                    if message == "å·²å­˜åœ¨":
                        skip_count += 1
                    else:
                        success_count += 1
                else:
                    error_count += 1
                    logger.error(f"å¤„ç†å¤±è´¥ {image_path}: {message}")
                
                pbar.update(1)
                
                # å®šæœŸæ¸…ç†GPUç¼“å­˜
                if torch.cuda.is_available() and (i % 100 == 0):
                    torch.cuda.empty_cache()
    
    # æ‰“å°ç»Ÿè®¡
    print("\n" + "="*70)
    print("ğŸ“Š å¤„ç†ç»Ÿè®¡:")
    print("="*70)
    print(f"âœ… æˆåŠŸå¤„ç†: {success_count} å¼ ")
    print(f"â­ï¸  è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: {skip_count} å¼ ")
    print(f"âŒ å¤„ç†å¤±è´¥: {error_count} å¼ ")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # éªŒè¯è¾“å‡º
    depth_files = list((output_dir / 'depth').rglob('*.png'))
    semantic_files = list((output_dir / 'semantic').rglob('*.png'))
    print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  æ·±åº¦å›¾: {len(depth_files)} ä¸ª")
    print(f"  è¯­ä¹‰å›¾: {len(semantic_files)} ä¸ª")
    
    print("\nâœ… é¢„å¤„ç†å®Œæˆï¼ç°åœ¨å¯ä»¥è¿è¡Œ:")
    print("python scripts/build_sharegpt_dataset.py --config configs/sharegpt_dataset_config.yaml")

def main():
    parser = argparse.ArgumentParser(description='é¢„å¤„ç†nuScenesæ•°æ®é›†çš„æ·±åº¦å’Œè¯­ä¹‰å›¾')
    parser.add_argument('--config', type=str, 
                       default='configs/sharegpt_dataset_config.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--max-samples', type=int, default=None,
                       help='æœ€å¤§å¤„ç†æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    parser.add_argument('--batch-size', type=int, default=1,
                       help='æ‰¹å¤„ç†å¤§å°')
    
    args = parser.parse_args()
    
    process_nuscenes_dataset(
        config_path=args.config,
        max_samples=args.max_samples,
        batch_size=args.batch_size
    )

if __name__ == "__main__":
    main()