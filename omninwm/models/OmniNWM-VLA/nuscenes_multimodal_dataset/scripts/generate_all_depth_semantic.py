#!/usr/bin/env python3
"""
æ‰¹é‡ç”Ÿæˆæ‰€æœ‰æ·±åº¦å’Œè¯­ä¹‰å›¾
ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œå¤šGPUå¹¶è¡Œå¤„ç†
"""

import os
import sys
import json
import argparse
import logging
import pickle
from pathlib import Path
from datetime import datetime
from tqdm import tqdm
import torch
import numpy as np
from PIL import Image
from typing import List, Tuple
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

class DepthSemanticGenerator:
    """æ·±åº¦å’Œè¯­ä¹‰å›¾æ‰¹é‡ç”Ÿæˆå™¨"""
    
    def __init__(self, config_path: str, output_dir: str = None, gpu_id: int = None):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            gpu_id: æŒ‡å®šä½¿ç”¨çš„GPU IDï¼ˆNoneè¡¨ç¤ºè‡ªåŠ¨é€‰æ‹©ï¼‰
        """
        self.config_path = config_path
        self.gpu_id = gpu_id
        self.setup_logging()
        self.load_config()
        self.setup_output_dir(output_dir)
        self.setup_processors()
        self.setup_progress_tracking()
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        gpu_suffix = f"_gpu{self.gpu_id}" if self.gpu_id is not None else ""
        log_file = f"depth_semantic_generation{gpu_suffix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        logging.basicConfig(
            level=logging.INFO,
            format=f'%(asctime)s - {f"GPU{self.gpu_id} - " if self.gpu_id is not None else ""}%(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        import yaml
        with open(self.config_path, 'r') as f:
            self.config = yaml.safe_load(f)
        
        self.dataroot = Path(self.config['dataset']['nuscenes_dataroot'])
        self.camera_channels = self.config['cameras']['channels']
        
    def setup_output_dir(self, output_dir: str = None):
        """è®¾ç½®è¾“å‡ºç›®å½•"""
        if output_dir:
            self.output_dir = Path(output_dir)
        else:
            self.output_dir = Path(self.config['dataset']['output_directory'])
        
        self.depth_dir = self.output_dir / 'depth'
        self.semantic_dir = self.output_dir / 'semantic'
        
        self.depth_dir.mkdir(parents=True, exist_ok=True)
        self.semantic_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        
    def setup_processors(self):
        """åˆå§‹åŒ–å¤„ç†å™¨"""
        # å¦‚æœæŒ‡å®šäº†GPU IDï¼Œè®¾ç½®CUDAè®¾å¤‡
        if self.gpu_id is not None:
            torch.cuda.set_device(self.gpu_id)
            device = f'cuda:{self.gpu_id}'
            self.logger.info(f"ä½¿ç”¨GPU {self.gpu_id}")
        else:
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        # åˆå§‹åŒ–æ·±åº¦å¤„ç†å™¨
        from src.processors.depth_processor import DepthProcessor
        depth_config = self.config.get('depth', {})
        self.depth_processor = DepthProcessor(
            model_name=depth_config.get('model_name', 'ZoeDepth'),
            model_path=depth_config.get('model_path'),
            device=device,
            use_local_weights=True if depth_config.get('model_path') else False
        )
        self.logger.info("æ·±åº¦å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆå§‹åŒ–è¯­ä¹‰å¤„ç†å™¨
        from src.processors.semantic_processor import SemanticProcessor
        semantic_config = self.config.get('semantic', {})
        self.semantic_processor = SemanticProcessor(
            model_name=semantic_config.get('model_name', 'SegFormer'),
            model_path=semantic_config.get('model_path'),
            device=device,
            use_local_weights=True if semantic_config.get('model_path') else False
        )
        self.logger.info("è¯­ä¹‰å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
    def setup_progress_tracking(self):
        """è®¾ç½®è¿›åº¦è·Ÿè¸ª"""
        self.progress_file = self.output_dir / 'generation_progress.pkl'
        self.processed_images = set()
        
        # åŠ è½½å·²å¤„ç†çš„å›¾åƒåˆ—è¡¨
        if self.progress_file.exists():
            with open(self.progress_file, 'rb') as f:
                self.processed_images = pickle.load(f)
            self.logger.info(f"å·²åŠ è½½è¿›åº¦: {len(self.processed_images)} å¼ å›¾åƒå·²å¤„ç†")
    
    def save_progress(self):
        """ä¿å­˜è¿›åº¦"""
        with open(self.progress_file, 'wb') as f:
            pickle.dump(self.processed_images, f)
    
    def collect_image_paths(self, max_samples: int = None) -> List[Tuple[str, str]]:
        """æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„å›¾åƒè·¯å¾„"""
        from nuscenes.nuscenes import NuScenes
        
        # åŠ è½½nuScenes
        self.logger.info("åŠ è½½nuScenesæ•°æ®é›†...")
        nusc = NuScenes(
            version=self.config['dataset']['nuscenes_version'],
            dataroot=str(self.dataroot),
            verbose=False
        )
        
        image_info = []  # [(image_path, sample_token), ...]
        sample_count = 0
        
        for scene in tqdm(nusc.scene, desc="æ”¶é›†å›¾åƒè·¯å¾„"):
            sample_token = scene['first_sample_token']
            
            while sample_token:
                sample = nusc.get('sample', sample_token)
                
                # è·å–æ‰€æœ‰æ‘„åƒå¤´çš„å›¾åƒ
                for camera in self.camera_channels:
                    if camera in sample['data']:
                        sample_data = nusc.get('sample_data', sample['data'][camera])
                        image_path = str(self.dataroot / sample_data['filename'])
                        
                        # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
                        if image_path not in self.processed_images:
                            image_info.append((image_path, f"{sample_token}_{camera}"))
                
                sample_token = sample['next']
                sample_count += 1
                
                if max_samples and sample_count >= max_samples:
                    break
            
            if max_samples and sample_count >= max_samples:
                break
        
        self.logger.info(f"æ‰¾åˆ° {len(image_info)} å¼ å¾…å¤„ç†å›¾åƒ")
        return image_info
    
    def process_image(self, image_path: str, image_id: str) -> Tuple[bool, str]:
        """å¤„ç†å•å¼ å›¾åƒ"""
        try:
            # æ„å»ºè¾“å‡ºè·¯å¾„
            rel_path = Path(image_path).relative_to(self.dataroot)
            depth_path = self.depth_dir / rel_path.parent / f"{rel_path.stem}_depth.png"
            semantic_path = self.semantic_dir / rel_path.parent / f"{rel_path.stem}_semantic.png"
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            depth_path.parent.mkdir(parents=True, exist_ok=True)
            semantic_path.parent.mkdir(parents=True, exist_ok=True)
            
            # è¯»å–å›¾åƒ
            image = Image.open(image_path).convert('RGB')
            
            # ç”Ÿæˆæ·±åº¦å›¾
            if not depth_path.exists():
                depth_map = self.depth_processor.process(image)  # è¿”å›å•ä½ï¼šç±³
                # ä¿å­˜ä¸º16ä½PNGï¼ˆç»Ÿä¸€ä½¿ç”¨æ¯«ç±³å•ä½ï¼‰
                depth_mm = np.clip(depth_map * 1000, 0, 65535).astype(np.uint16)
                Image.fromarray(depth_mm).save(depth_path)
            
            # ç”Ÿæˆè¯­ä¹‰å›¾
            if not semantic_path.exists():
                semantic_map = self.semantic_processor.process(image)
                # ä¿å­˜ä¸º8ä½ç´¢å¼•å›¾
                Image.fromarray(semantic_map.astype(np.uint8)).save(semantic_path)
            
            return True, "æˆåŠŸ"
            
        except Exception as e:
            return False, str(e)
    
    def run(self, max_samples: int = None, batch_size: int = 10):
        """è¿è¡Œæ‰¹é‡ç”Ÿæˆ"""
        print("\n" + "="*70)
        print("ğŸš€ å¼€å§‹æ‰¹é‡ç”Ÿæˆæ·±åº¦å’Œè¯­ä¹‰å›¾")
        print("="*70)
        
        # æ”¶é›†å›¾åƒè·¯å¾„
        image_info = self.collect_image_paths(max_samples)
        
        if not image_info:
            print("âœ… æ‰€æœ‰å›¾åƒå·²å¤„ç†å®Œæˆï¼")
            return
        
        # å¤„ç†å›¾åƒ
        success_count = 0
        error_count = 0
        
        with tqdm(total=len(image_info), desc="å¤„ç†è¿›åº¦") as pbar:
            for i, (image_path, image_id) in enumerate(image_info):
                # å¤„ç†å›¾åƒ
                success, message = self.process_image(image_path, image_id)
                
                if success:
                    success_count += 1
                    self.processed_images.add(image_path)
                else:
                    error_count += 1
                    self.logger.error(f"å¤„ç†å¤±è´¥ {image_path}: {message}")
                
                # æ›´æ–°è¿›åº¦æ¡
                pbar.update(1)
                pbar.set_postfix({
                    'æˆåŠŸ': success_count,
                    'å¤±è´¥': error_count
                })
                
                # å®šæœŸä¿å­˜è¿›åº¦å’Œæ¸…ç†ç¼“å­˜
                if (i + 1) % batch_size == 0:
                    self.save_progress()
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
        
        # æœ€ç»ˆä¿å­˜è¿›åº¦
        self.save_progress()
        
        # æ‰“å°ç»Ÿè®¡
        print("\n" + "="*70)
        print("ğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
        print("="*70)
        print(f"âœ… æˆåŠŸå¤„ç†: {success_count} å¼ ")
        print(f"âŒ å¤„ç†å¤±è´¥: {error_count} å¼ ")
        print(f"ğŸ“ æ·±åº¦å›¾ç›®å½•: {self.depth_dir}")
        print(f"ğŸ“ è¯­ä¹‰å›¾ç›®å½•: {self.semantic_dir}")
        
        # éªŒè¯è¾“å‡º
        depth_files = list(self.depth_dir.rglob('*.png'))
        semantic_files = list(self.semantic_dir.rglob('*.png'))
        print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"  æ·±åº¦å›¾: {len(depth_files)} ä¸ª")
        print(f"  è¯­ä¹‰å›¾: {len(semantic_files)} ä¸ª")
        
        if success_count > 0:
            print("\nâœ… æ·±åº¦å’Œè¯­ä¹‰å›¾ç”Ÿæˆå®Œæˆï¼")
            print("\nä¸‹ä¸€æ­¥: è¿è¡ŒShareGPTæ•°æ®é›†ç”Ÿæˆ")
            print("python scripts/build_sharegpt_dataset.py --config configs/sharegpt_dataset_config.yaml")

def process_images_on_gpu(args):
    """åœ¨æŒ‡å®šGPUä¸Šå¤„ç†ä¸€æ‰¹å›¾åƒ
    ä½¿ç”¨å•ä¸ªå‚æ•°ä»¥å…¼å®¹multiprocessing.Pool
    """
    gpu_id, image_batch, config_path, output_dir = args
    
    # è®¾ç½®å½“å‰è¿›ç¨‹ä½¿ç”¨çš„GPU
    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
    
    # åœ¨å­è¿›ç¨‹ä¸­å¯¼å…¥å¿…è¦çš„åº“
    import torch
    import sys
    from pathlib import Path
    sys.path.append(str(Path(__file__).parent.parent))
    
    # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹
    from scripts.generate_all_depth_semantic import DepthSemanticGenerator
    generator = DepthSemanticGenerator(
        config_path=config_path,
        output_dir=output_dir,
        gpu_id=None  # ä½¿ç”¨ç¯å¢ƒå˜é‡è®¾ç½®çš„GPU
    )
    
    success_count = 0
    error_count = 0
    
    # å¤„ç†æ¯å¼ å›¾åƒ
    for image_path, image_id in tqdm(image_batch, desc=f"GPU {gpu_id}"):
        success, message = generator.process_image(image_path, image_id)
        
        if success:
            success_count += 1
            generator.processed_images.add(image_path)
        else:
            error_count += 1
            generator.logger.error(f"å¤„ç†å¤±è´¥ {image_path}: {message}")
        
        # å®šæœŸä¿å­˜è¿›åº¦å’Œæ¸…ç†ç¼“å­˜
        if (success_count + error_count) % 10 == 0:
            generator.save_progress()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
    
    # æœ€ç»ˆä¿å­˜è¿›åº¦
    generator.save_progress()
    generator.logger.info(f"GPU {gpu_id} å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {error_count}")
    
    return success_count, error_count

def run_multi_gpu(config_path: str, output_dir: str = None, 
                  max_samples: int = None, num_gpus: int = 4):
    """å¤šGPUå¹¶è¡Œè¿è¡Œ"""
    import yaml
    
    # è®¾ç½®multiprocessingä½¿ç”¨spawnæ–¹å¼ä»¥æ”¯æŒCUDA
    try:
        mp.set_start_method('spawn')
    except RuntimeError:
        pass  # å·²ç»è®¾ç½®è¿‡äº†
    
    # è¯»å–é…ç½®
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶ç”Ÿæˆå™¨æ¥æ”¶é›†å›¾åƒè·¯å¾„
    temp_generator = DepthSemanticGenerator(config_path, output_dir)
    all_images = temp_generator.collect_image_paths(max_samples)
    
    if not all_images:
        print("âœ… æ‰€æœ‰å›¾åƒå·²å¤„ç†å®Œæˆï¼")
        return
    
    # æ£€æŸ¥å¯ç”¨GPUæ•°é‡
    available_gpus = torch.cuda.device_count()
    num_gpus = min(num_gpus, available_gpus)
    print(f"\nä½¿ç”¨ {num_gpus} ä¸ªGPU (å¯ç”¨: {available_gpus})")
    
    # å°†å›¾åƒåˆ†é…åˆ°å„ä¸ªGPU
    images_per_gpu = len(all_images) // num_gpus
    gpu_tasks = []
    
    for i in range(num_gpus):
        start_idx = i * images_per_gpu
        if i == num_gpus - 1:
            # æœ€åä¸€ä¸ªGPUå¤„ç†å‰©ä½™çš„æ‰€æœ‰å›¾åƒ
            batch = all_images[start_idx:]
        else:
            batch = all_images[start_idx:start_idx + images_per_gpu]
        
        gpu_tasks.append((i, batch, config_path, output_dir))
    
    print(f"æ€»å…± {len(all_images)} å¼ å›¾åƒï¼Œæ¯ä¸ªGPUå¤„ç†çº¦ {images_per_gpu} å¼ ")
    print("="*70)
    print("ğŸš€ å¼€å§‹å¤šGPUå¹¶è¡Œå¤„ç†")
    print("="*70)
    
    # ä½¿ç”¨multiprocessing.Pool
    with mp.Pool(processes=num_gpus) as pool:
        results = pool.map(process_images_on_gpu, gpu_tasks)
    
    # ç»Ÿè®¡æ€»ç»“æœ
    total_success = sum(r[0] for r in results)
    total_error = sum(r[1] for r in results)
    
    for i, (success, error) in enumerate(results):
        print(f"GPU {i} å®Œæˆ: æˆåŠŸ {success}, å¤±è´¥ {error}")
    
    # æ‰“å°æœ€ç»ˆç»Ÿè®¡
    print("\n" + "="*70)
    print("ğŸ“Š å¤šGPUå¤„ç†å®Œæˆç»Ÿè®¡:")
    print("="*70)
    print(f"âœ… æˆåŠŸå¤„ç†: {total_success} å¼ ")
    print(f"âŒ å¤„ç†å¤±è´¥: {total_error} å¼ ")
    
    if total_success > 0:
        print("\nâœ… æ·±åº¦å’Œè¯­ä¹‰å›¾ç”Ÿæˆå®Œæˆï¼")
        print("\nä¸‹ä¸€æ­¥: è¿è¡ŒShareGPTæ•°æ®é›†ç”Ÿæˆ")
        print("python scripts/build_sharegpt_dataset.py --config configs/sharegpt_dataset_config.yaml")

def main():
    parser = argparse.ArgumentParser(description='æ‰¹é‡ç”ŸæˆnuScenesæ·±åº¦å’Œè¯­ä¹‰å›¾')
    parser.add_argument('--config', type=str, 
                       default='configs/sharegpt_dataset_config.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', type=str, default=None,
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„ï¼‰')
    parser.add_argument('--max-samples', type=int, default=None,
                       help='æœ€å¤§å¤„ç†æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    parser.add_argument('--batch-size', type=int, default=10,
                       help='æ‰¹å¤„ç†å¤§å°ï¼ˆå¤šå°‘å¼ å›¾åä¿å­˜è¿›åº¦ï¼‰')
    parser.add_argument('--multi-gpu', action='store_true',
                       help='å¯ç”¨å¤šGPUå¹¶è¡Œå¤„ç†')
    parser.add_argument('--num-gpus', type=int, default=4,
                       help='ä½¿ç”¨çš„GPUæ•°é‡ï¼ˆé»˜è®¤4ä¸ªï¼‰')
    
    args = parser.parse_args()
    
    if args.multi_gpu:
        # å¤šGPUæ¨¡å¼
        run_multi_gpu(
            config_path=args.config,
            output_dir=args.output_dir,
            max_samples=args.max_samples,
            num_gpus=args.num_gpus
        )
    else:
        # å•GPUæ¨¡å¼
        generator = DepthSemanticGenerator(
            config_path=args.config,
            output_dir=args.output_dir
        )
        
        generator.run(
            max_samples=args.max_samples,
            batch_size=args.batch_size
        )

if __name__ == "__main__":
    main()