#!/usr/bin/env python3
"""
è¿‡æ‹Ÿåˆç›‘æ§è„šæœ¬
å®æ—¶ç›‘æ§è®­ç»ƒï¼Œè‡ªåŠ¨æ£€æµ‹è¿‡æ‹Ÿåˆå¹¶æä¾›å»ºè®®
"""

import json
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
from typing import Dict, List
import argparse


class OverfittingMonitor:
    """è¿‡æ‹Ÿåˆç›‘æ§å™¨"""
    
    def __init__(self, checkpoint_dir: str):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'epoch': []
        }
        
    def analyze(self) -> Dict:
        """åˆ†æè®­ç»ƒçŠ¶æ€"""
        # è¯»å–è®­ç»ƒæ—¥å¿—
        self._load_history()
        
        results = {
            'is_overfitting': False,
            'overfitting_epoch': None,
            'suggestions': [],
            'metrics': {}
        }
        
        if len(self.history['train_loss']) < 5:
            results['suggestions'].append("éœ€è¦æ›´å¤šepochæ‰èƒ½åˆ¤æ–­")
            return results
        
        # 1. æ£€æµ‹è¿‡æ‹Ÿåˆ
        train_loss = np.array(self.history['train_loss'])
        val_loss = np.array(self.history['val_loss'])
        
        # è®¡ç®—losså·®è·
        loss_gap = val_loss - train_loss
        recent_gap = loss_gap[-5:].mean()  # æœ€è¿‘5ä¸ªepoch
        
        # éªŒè¯é›†lossè¶‹åŠ¿
        val_trend = np.polyfit(range(len(val_loss[-10:])), val_loss[-10:], 1)[0]
        
        # åˆ¤æ–­æ ‡å‡†
        if recent_gap > 0.5 and val_trend > 0:
            results['is_overfitting'] = True
            results['overfitting_epoch'] = self._find_overfitting_point()
            
        # 2. è®¡ç®—æŒ‡æ ‡
        results['metrics'] = {
            'train_loss': train_loss[-1],
            'val_loss': val_loss[-1],
            'loss_gap': recent_gap,
            'val_trend': val_trend,
            'best_val_loss': val_loss.min(),
            'best_epoch': val_loss.argmin() + 1
        }
        
        # 3. ç”Ÿæˆå»ºè®®
        results['suggestions'] = self._generate_suggestions(results)
        
        return results
    
    def _find_overfitting_point(self) -> int:
        """æ‰¾åˆ°å¼€å§‹è¿‡æ‹Ÿåˆçš„epoch"""
        val_loss = self.history['val_loss']
        
        # æ‰¾åˆ°éªŒè¯losså¼€å§‹ä¸Šå‡çš„ç‚¹
        for i in range(5, len(val_loss)):
            if all(val_loss[i] > val_loss[i-j] for j in range(1, 4)):
                return i
        return len(val_loss)
    
    def _generate_suggestions(self, analysis: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []
        metrics = analysis['metrics']
        
        if analysis['is_overfitting']:
            suggestions.append(f"âš ï¸ æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆï¼ä»epoch {analysis['overfitting_epoch']}å¼€å§‹")
            suggestions.append("å»ºè®®ç«‹å³é‡‡å–ä»¥ä¸‹æªæ–½ï¼š")
            
            # æ ¹æ®gapå¤§å°ç»™å‡ºå»ºè®®
            gap = metrics['loss_gap']
            if gap > 1.0:
                suggestions.append("â€¢ ä¸¥é‡è¿‡æ‹Ÿåˆï¼šå¢åŠ dropoutåˆ°0.4-0.5")
                suggestions.append("â€¢ å‡å°‘å­¦ä¹ ç‡50%")
                suggestions.append("â€¢ è€ƒè™‘æ—©åœ")
            elif gap > 0.5:
                suggestions.append("â€¢ ä¸­åº¦è¿‡æ‹Ÿåˆï¼šå¢åŠ weight_decayåˆ°0.1")
                suggestions.append("â€¢ å¢åŠ æ•°æ®å¢å¼º")
                suggestions.append("â€¢ å‡å°‘æ¨¡å‹å¤æ‚åº¦")
            
        else:
            # æ£€æŸ¥æ˜¯å¦æ¬ æ‹Ÿåˆ
            if metrics['train_loss'] > 1.0:
                suggestions.append("â€¢ è®­ç»ƒlossä»ç„¶å¾ˆé«˜ï¼Œå¯èƒ½æ¬ æ‹Ÿåˆ")
                suggestions.append("â€¢ å¢åŠ æ¨¡å‹å®¹é‡æˆ–è®­ç»ƒæ›´é•¿æ—¶é—´")
            
            # æ£€æŸ¥å­¦ä¹ æ˜¯å¦åœæ»
            if abs(metrics['val_trend']) < 0.001:
                suggestions.append("â€¢ å­¦ä¹ åœæ»ï¼Œè€ƒè™‘è°ƒæ•´å­¦ä¹ ç‡")
        
        # TMIç‰¹å®šå»ºè®®
        suggestions.append("\nğŸ“Š TMIæ¨¡å—ç‰¹å®šå»ºè®®ï¼š")
        suggestions.append(f"â€¢ æœ€ä½³checkpoint: epoch {metrics['best_epoch']}")
        suggestions.append(f"â€¢ å½“å‰loss gap: {metrics['loss_gap']:.3f}")
        
        if metrics['loss_gap'] > 0.3:
            suggestions.append("â€¢ è€ƒè™‘å†»ç»“æ›´å¤šTMIå±‚ï¼Œåªè®­ç»ƒèåˆæ ¸å¿ƒ")
            suggestions.append("â€¢ ä½¿ç”¨R-Dropæˆ–å…¶ä»–ä¸€è‡´æ€§æ­£åˆ™åŒ–")
        
        return suggestions
    
    def plot_curves(self, save_path: str = "training_curves.png"):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        if not self.history['train_loss']:
            print("æ²¡æœ‰æ•°æ®å¯ç»˜åˆ¶")
            return
        
        fig, axes = plt.subplots(1, 2, figsize=(12, 4))
        
        # Lossæ›²çº¿
        axes[0].plot(self.history['epoch'], self.history['train_loss'], 
                    label='Train Loss', marker='o')
        axes[0].plot(self.history['epoch'], self.history['val_loss'], 
                    label='Val Loss', marker='s')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].set_title('Training vs Validation Loss')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # Loss Gap
        gap = np.array(self.history['val_loss']) - np.array(self.history['train_loss'])
        axes[1].plot(self.history['epoch'], gap, 
                    label='Val-Train Gap', marker='d', color='red')
        axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)
        axes[1].axhline(y=0.3, color='orange', linestyle='--', 
                       alpha=0.5, label='Overfitting Threshold')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('Loss Gap')
        axes[1].set_title('Overfitting Indicator')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"ğŸ“ˆ è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ° {save_path}")
    
    def _load_history(self):
        """ä»checkpointåŠ è½½è®­ç»ƒå†å²"""
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦ä»tensorboardæˆ–è®­ç»ƒæ—¥å¿—è¯»å–
        # ç¤ºä¾‹ï¼šä»trainer_state.jsonè¯»å–
        state_file = self.checkpoint_dir / "trainer_state.json"
        if state_file.exists():
            with open(state_file) as f:
                state = json.load(f)
                # è§£æè®­ç»ƒå†å²
                for entry in state.get('log_history', []):
                    if 'loss' in entry:
                        self.history['train_loss'].append(entry['loss'])
                    if 'eval_loss' in entry:
                        self.history['val_loss'].append(entry['eval_loss'])
                    if 'epoch' in entry:
                        self.history['epoch'].append(entry['epoch'])


def main():
    parser = argparse.ArgumentParser(description='è¿‡æ‹Ÿåˆç›‘æ§')
    parser.add_argument(
        '--checkpoint-dir',
        type=str,
        default='/code/VLA/outputs/stage1_tmi_fixed',
        help='Checkpointç›®å½•'
    )
    parser.add_argument(
        '--plot',
        action='store_true',
        help='ç»˜åˆ¶è®­ç»ƒæ›²çº¿'
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºç›‘æ§å™¨
    monitor = OverfittingMonitor(args.checkpoint_dir)
    
    # åˆ†æ
    print("\n" + "="*60)
    print("ğŸ” è¿‡æ‹Ÿåˆåˆ†ææŠ¥å‘Š")
    print("="*60)
    
    results = monitor.analyze()
    
    # æ‰“å°ç»“æœ
    if results['is_overfitting']:
        print("âš ï¸  çŠ¶æ€: è¿‡æ‹Ÿåˆï¼")
        print(f"   å¼€å§‹epoch: {results['overfitting_epoch']}")
    else:
        print("âœ… çŠ¶æ€: æ­£å¸¸è®­ç»ƒ")
    
    print("\nğŸ“Š å…³é”®æŒ‡æ ‡:")
    for key, value in results['metrics'].items():
        if isinstance(value, float):
            print(f"   {key}: {value:.4f}")
        else:
            print(f"   {key}: {value}")
    
    print("\nğŸ’¡ å»ºè®®:")
    for suggestion in results['suggestions']:
        print(f"   {suggestion}")
    
    # ç»˜å›¾
    if args.plot:
        monitor.plot_curves()
    
    print("="*60)


if __name__ == '__main__':
    main()